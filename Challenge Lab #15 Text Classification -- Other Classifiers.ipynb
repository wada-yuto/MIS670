{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565cee16",
   "metadata": {},
   "source": [
    "# Model fit\n",
    "\n",
    "<img alt=\"\" class=\"ce kx ky c\" width=\"700\" height=\"249\" loading=\"lazy\" role=\"presentation\" src=\"https://miro.medium.com/max/1400/1*dpUnwfXqnU5Kd-gfafgIgQ.png\">\n",
    "\n",
    "**Overfit Model:** Overfitting occurs when a statistical model or machine learning algorithm captures the noise of the data. Intuitively, overfitting occurs when the model or the algorithm fits the data too well.\n",
    "\n",
    "Overfitting a model result in good accuracy for training data set but poor results on new data sets. Such a model is not of any use in the real world as it is not able to predict outcomes for new cases.\n",
    "\n",
    "**Underfit Model:** Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. Intuitively, underfitting occurs when the model or the algorithm does not fit the data well enough. Underfitting is often a result of an excessively simple model. By simple we mean that the missing data is not handled properly, no outlier treatment, removing of irrelevant features or features which do not contribute much to the predictor variable.\n",
    "\n",
    "source:https://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646ac13",
   "metadata": {},
   "source": [
    "## Split the data into TRAIN, TEXT, and VELIDATION to check the model fit\n",
    "\n",
    "**Definition of Train-Valid-Test Split**\n",
    "\n",
    "Train-Valid-Test split is a technique to evaluate the performance of your machine learning model â€” classification or regression alike. You take a given dataset and divide it into three subsets. A brief description of the role of each of these datasets is below.\n",
    "\n",
    ">**Train Dataset**\n",
    "Set of data used for learning (by the model), that is, to fit the parameters to the machine learning model\n",
    "\n",
    ">**Valid Dataset**\n",
    "Set of data used to provide an unbiased evaluation of a model fitted on the training dataset while tuning model hyperparameters.\n",
    "Also play a role in other forms of model preparation, such as feature selection, threshold cut-off selection.\n",
    "It is used to validate the generalisation ability of the model or for early stopping, during the training process.\n",
    "\n",
    ">**Test Dataset**\n",
    "Set of data used to provide an unbiased evaluation of a final model fitted on the training dataset.\n",
    "\n",
    "### Split validation (Randomly split the data into three datasets)\n",
    "\n",
    "<img width=\"500\" height=\"219\" src=\"https://miro.medium.com/max/1400/1*f2KznlrIdj1MeobprVGBtg.png\">\n",
    "\n",
    "source:https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c\n",
    "\n",
    "### *Hypeparameter tuning*\n",
    "\n",
    "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\n",
    "\n",
    "The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data. The objective function takes a tuple of hyperparameters and returns the associated loss. **Cross-validation is often used to estimate this generalization performance.**\n",
    "\n",
    "source: https://en.wikipedia.org/wiki/Hyperparameter_optimization\n",
    "\n",
    "\n",
    "<img width=\"500\" height=\"530\" src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/61568656a13218cdde7f6166_training-data-validation-test.png\" alt=\"Training, test, and validation data\">\n",
    "\n",
    "source:https://www.v7labs.com/blog/train-validation-test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46b245",
   "metadata": {},
   "source": [
    "> **Method 1: conduct train_test_split twice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de264c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SMS = pd.read_csv('SpamSMStraining.txt', sep = '\\t', header=None, names=[\"label\", \"sms\"])\n",
    "SMS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c0b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining X and Y (Y is what you want to predict)\n",
    "X = SMS['sms']\n",
    "y = SMS[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935aadfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,)\n",
      "(4457,)\n",
      "(557,)\n",
      "(557,)\n",
      "(558,)\n",
      "(558,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train1, X_rem, y_train1, y_rem = train_test_split(X,y, train_size=0.8) \n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "X_valid1, X_test1, y_valid1, y_test1 = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train1.shape), print(y_train1.shape)\n",
    "print(X_valid1.shape), print(y_valid1.shape)\n",
    "print(X_test1.shape), print(y_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c3fd3",
   "metadata": {},
   "source": [
    "> **Method 2: use train_valid_test_split**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc25393",
   "metadata": {},
   "source": [
    "install packages\n",
    "\n",
    "! pip install fast_ml\n",
    "\n",
    "https://anaconda.org/bioconda/fastml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0cdbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 1)\n",
      "(4457,)\n",
      "(557, 1)\n",
      "(557,)\n",
      "(558, 1)\n",
      "(558,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "X_train2, y_train2, X_valid2, y_valid2, X_test2, y_test2 = train_valid_test_split(SMS, target = 'label', #target is y = teams['R'] \n",
    "                                                                            train_size=0.8, valid_size=0.1, test_size=0.1)\n",
    "\n",
    "print(X_train2.shape), print(y_train2.shape)\n",
    "print(X_valid2.shape), print(y_valid2.shape)\n",
    "print(X_test2.shape), print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72491b",
   "metadata": {},
   "source": [
    "### Model fit for Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815c12a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953405017921147"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Creating a model based on Multinomial Naive Bayes using make_pipeline\n",
    "modelnb = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Training the model with the train data\n",
    "modelnb.fit(X_train1, y_train1) \n",
    "\n",
    "# Creating labels for the test data\n",
    "y_prednb = modelnb.predict(X_test1)\n",
    "\n",
    "acc_NB_test = accuracy_score(y_test1, y_prednb)\n",
    "acc_NB_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c1af18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676840215439856"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for validation data\n",
    "y_val_prednb = modelnb.predict(X_valid1)\n",
    "\n",
    "acc_NB_val = accuracy_score(y_valid1, y_val_prednb)\n",
    "acc_NB_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cef71f",
   "metadata": {},
   "source": [
    ">**Numberic ML Training and Loss**\n",
    "\n",
    "Loss is the penalty for a bad prediction. That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples. For example, Figure 3 shows a high loss model on the left and a low loss model on the right. Note the following about the figure:\n",
    "\n",
    "<img src=\"https://developers.google.com/machine-learning/crash-course/images/LossSideBySide.png\" height=\"200\" alt=\"Two Cartesian plots, each showing a line and some data points. In the first plot, the line is a terrible fit for the data, so the loss is high. In the second plot, the line is a a better fit for the data, so the loss is low.\">\n",
    "\n",
    "**Figure 3. High loss in the left model; low loss in the right model.**\n",
    "\n",
    "**Mean square error (MSE)** is the average squared loss per example over the whole dataset.\n",
    "\n",
    "source:https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e767e",
   "metadata": {},
   "source": [
    "# Model Validation -- Split the dataset\n",
    "\n",
    "When building a predictive model, we split the original data into two datasets: **training dataset and testing (validation) dataset**. This is called **\"split validation\"**, a type of **\"model validation\"**\n",
    "- A predictive model is built using the **training dataset** and **the model quality** is assessed as the model is applied into the **testing (validation) dataset** (See Appendix for more details)\n",
    "\n",
    "> **Two types of model validation**: \n",
    " 1. **split validation** (70% of the original data as training and the other 30% as testing dataset)\n",
    " 2. **cross validation**  \n",
    "\n",
    "This concept is same as **taking ACT exam**. There are two periods: **prep / practice test** and **actual testing**. **prep / practice test** is like **training data** and **actual testing** is like **testing data**. Your final ACT score is based on **actual test**, not practice test. Likewise, the **accuracy of predictive (regression) model** is based on **testing dataset**. \n",
    "\n",
    "> **What is k-Fold Cross-Validation?**\n",
    "\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "source:https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    "<img alt=\"\" class=\"ce kx ky c\" width=\"700\" height=\"314\" loading=\"lazy\" role=\"presentation\" src=\"https://miro.medium.com/max/1400/1*AAwIlHM8TpAVe4l2FihNUQ.png\">\n",
    "\n",
    "source:https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbde7c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "      <th>Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms  Dummy\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      1\n",
       "1   ham                      Ok lar... Joking wif u oni...      1\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      0\n",
       "3   ham  U dun say so early hor... U c already then say...      1\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label to dummy variables\n",
    "SMS[\"Dummy\"] = SMS[\"label\"].map({'ham': 1, 'spam': 0})\n",
    "SMS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff3f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using StratifiedKFold for cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7859812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457 4457 1115 1115\n",
      "4457 4457 1115 1115\n",
      "4458 4458 1114 1114\n",
      "4458 4458 1114 1114\n",
      "4458 4458 1114 1114\n"
     ]
    }
   ],
   "source": [
    "#5-fold cross-validation\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5) #split the data into equally 5 parts\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(len(X_train), len(y_train),len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83423199",
   "metadata": {},
   "source": [
    "# Classifier 2 -- Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454bf35",
   "metadata": {},
   "source": [
    "The objective of the support vector machine algorithm is to find **a hyperplane in an N-dimensional space(N â€” the number of features) that distinctly classifies the data points.**\n",
    "\n",
    "<tr>\n",
    "<td> <img alt=\"\" class=\"ce kx ky c\" width=\"210\" height=\"206\" loading=\"eager\" role=\"presentation\" src=\"https://miro.medium.com/max/600/0*9jEWNXTAao7phK-5.png\" /> </td>\n",
    "<td> <img alt=\"\" class=\"ce kx ky c\" width=\"210\" height=\"206\" loading=\"eager\" role=\"presentation\" src=\"https://miro.medium.com/max/600/0*0o8xIA4k3gXUDCFU.png\" /> </td>\n",
    "</tr>\n",
    "\n",
    "To separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, **i.e the maximum distance between data points of both classes**. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.\n",
    "\n",
    "<img alt=\"\" class=\"ce kx ky c\" width=\"700\" height=\"297\" loading=\"eager\" role=\"presentation\" src=\"https://miro.medium.com/max/1400/1*ZpkLQf2FNfzfH4HXeMw4MQ.png\">\n",
    "\n",
    "<img alt=\"\" class=\"ce kx ky c\" width=\"700\" height=\"362\" loading=\"lazy\" role=\"presentation\" src=\"https://miro.medium.com/max/1400/0*ecA4Ls8kBYSM5nza.jpg\">\n",
    "\n",
    "source:https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b641eb",
   "metadata": {},
   "source": [
    "## It is not always linear \n",
    "\n",
    "by changing the kernel in SVC() function\n",
    "\n",
    "`kernel{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™} or callable, default=â€™rbfâ€™`\n",
    "Specifies the kernel type to be used in the algorithm. If none is given, â€˜rbfâ€™ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples).\n",
    "\n",
    "rbf : radial basis function, for more:https://en.wikipedia.org/wiki/Radial_basis_function_kernel#:~:text=In%20machine%20learning%2C%20the%20radial,in%20support%20vector%20machine%20classification.\n",
    "\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/Circles.png\" alt=\"\" width=\"383\" height=\"252\" class=\"aligncenter size-full wp-image-824428\">\n",
    "\n",
    "<img alt=\"\" class=\"ce ok ve c\" width=\"491\" height=\"387\" loading=\"lazy\" role=\"presentation\" src=\"https://miro.medium.com/max/982/1*J0k7TxTLoL5ZG-Hq6v34Jg.png\">\n",
    "\n",
    "source:\n",
    "1. https://www.geeksforgeeks.org/ml-using-svm-to-perform-classification-on-a-non-linear-dataset/\n",
    "2. https://linguisticmaz.medium.com/support-vector-machines-explained-ii-f2688fbf02ae\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf4879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e7f4d",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f6538ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam']\n",
      "['spam' 'spam' 'spam' 'spam' 'spam' 'spam' 'ham' 'spam' 'spam' 'spam']\n",
      "['spam' 'spam' 'spam' 'spam' 'spam' 'spam' 'spam' 'spam' 'spam' 'ham']\n",
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham']\n",
      "['spam' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham']\n",
      "Mean accuracy:  0.9782837268840924\n",
      "Std for accuracy:  0.0023036860904803442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#SVM using 5-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5) #split the data into equally 5 parts\n",
    "\n",
    "accuracy =[]\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #tokenize the words and give each word a value\n",
    "    tfIdfVectorizer=TfidfVectorizer(decode_error ='ignore', use_idf=True,stop_words='english') # we removed stopwords here\n",
    "    X_train_tfidf = tfIdfVectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfIdfVectorizer.transform(X_test)\n",
    "    SVM = svm.SVC()# Build the SVM classifier\n",
    "    SVM.fit(X_train_tfidf, y_train)# Train it on the entire training data set\n",
    "    y_pred = SVM.predict(X_test_tfidf)\n",
    "    print(y_pred[:10])\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "accuracy = np.array(accuracy)\n",
    "print('Mean accuracy: ', np.mean(accuracy, axis=0))\n",
    "print('Std for accuracy: ', np.std(accuracy, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c38ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98295964 0.9838565  0.98384201 0.97845601 0.98473968]\n",
      "0.9827707690945247\n"
     ]
    }
   ],
   "source": [
    "# use cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "svm_pipeline = Pipeline([('tfidf', TfidfVectorizer(decode_error ='ignore', stop_words='english', use_idf=True)), \n",
    "                         ('clf', svm.SVC(kernel='linear', probability=True))])#kernel{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™} or callable, default=â€™rbfâ€™\n",
    "\n",
    "#svm_Mpipline = make_pipeline(TfidfVectorizer(decode_error ='ignore', stop_words='english', use_idf=True), svm.SVC(kernel='linear', probability=True))\n",
    "\n",
    "SVMcv = cross_val_score(svm_pipeline, X, y, scoring='accuracy', cv=5) # 5-fold cross-validation\n",
    "print(SVMcv)\n",
    "print(SVMcv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9a2fbf",
   "metadata": {},
   "source": [
    "<table><thead><tr><th><p style=\"text-align:center\"><strong>pipeline</strong></p></th><th><p style=\"text-align:center\"><strong>make_pipeline</strong></p></th></tr></thead><tbody><tr><td>The pipeline requires naming the steps, manually.&nbsp;</td><td>make_pipeline names the steps, automatically.&nbsp;</td></tr><tr><td>Names are defined explicitly, without rules.</td><td>Names are generated automatically using a straightforward rule (lower case of the estimator).</td></tr><tr><td>Names cannot be changed based on the transformer or estimator used.</td><td>&nbsp;Names are readable, short, and easy to understand, and can be changed based on the estimator used.</td></tr></tbody></table>\n",
    "\n",
    "source:https://www.geeksforgeeks.org/what-is-the-difference-between-pipeline-and-make_pipeline-in-scikit/#:~:text=The%20pipeline%20requires%20naming%20the,lower%20case%20of%20the%20estimator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3eb38",
   "metadata": {},
   "source": [
    "##  Feature engineering (Words to Vectors)\n",
    "\n",
    "### Bag of words\n",
    "\n",
    "- Tokenization\n",
    "- Word Frequency\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Remove stopwords\n",
    "\n",
    "\n",
    ">**TF-IDF**\n",
    "to find meaning of sentences consisting of words and cancels out the incapabilities of Bag of Words technique which is good for text classification or for helping a machine read words in numbers.\n",
    "\n",
    "**You also can use CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b6066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Documentation:https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vec = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5823101",
   "metadata": {},
   "source": [
    "### Split validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a16982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 4457, 1115, 1115)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and test sets (80-20): X = corpus; y = classifications\n",
    "SX_train, SX_test, Sy_train, Sy_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "len(SX_train), len(Sy_train), len(SX_test), len(Sy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59de234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()), ('svc', SVC())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsvm = make_pipeline(TfidfVectorizer(), svm.SVC()) # we did not remove stopwords here\n",
    "modelsvm.fit(SX_train,Sy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba776fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "Sy_pred = modelsvm.predict(SX_test)\n",
    "print(Sy_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3673f2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748878923766816"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy \n",
    "acc_SVM = accuracy_score(Sy_test, Sy_pred)\n",
    "acc_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50bf0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question' => spam\n",
      "'Even my brother is not like to speak with me. They treat me like aids patent.' => ham\n",
      "\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9\" => ham\n",
      "'hello, thank you' => ham\n",
      "'To claim txt DIS to 87121' => spam\n",
      "'SNAP for free pics' => ham\n",
      "'Call 30303 for free prizes!!' => spam\n"
     ]
    }
   ],
   "source": [
    "# let's try some new data\n",
    "\n",
    "docs_new = [\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question\",\n",
    "            \"Even my brother is not like to speak with me. They treat me like aids patent.\",\n",
    "             \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9\",\n",
    "            \"hello, thank you\",\n",
    "           \"To claim txt DIS to 87121\",\n",
    "                \"SNAP for free pics\",\n",
    "           \"Call 30303 for free prizes!!\"]\n",
    "\n",
    "predicted = modelsvm.predict(docs_new)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print(('%r => %s' % (doc, category)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc75b88",
   "metadata": {},
   "source": [
    "### Changing parameters to improve the model accuracy\n",
    "\n",
    "e.g., removing stopwords, using stemming words, using ngrams, removing too frequent words, removing too rare words\n",
    "\n",
    "- TfidfVectorizer(input=â€™contentâ€™, encoding=â€™utf-8â€™, decode_error=â€™strictâ€™, strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer=â€™wordâ€™, stop_words=None, token_pattern=â€™(?u)\\b\\w\\w+\\bâ€™, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class â€˜numpy.int64â€™>, norm=â€™l2â€™, use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "- max_df : float in range [0.0, 1.0] or int, default=1.0 \n",
    "When building the vocabulary ignore terms that have a **document frequency** strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "    - For example, max_df = 0.7 ==> This removes words which appear in more than 70% of the corpus (**removing frequent words**).\n",
    "<br><br>    \n",
    "- min_df : float in range [0.0, 1.0] or int, default=1\n",
    "When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "- For example, min_df = 5 ==> This removes words which appear in less than five documents (**removing rare words**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234fd80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968609865470852"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "modelsvm2 = make_pipeline(TfidfVectorizer(stop_words='english'), svm.SVC()) \n",
    "modelsvm2.fit(SX_train,Sy_train)\n",
    "Sy_pred2 = modelsvm2.predict(SX_test)\n",
    "acc_SVM2 = accuracy_score(Sy_test, Sy_pred2)\n",
    "\n",
    "acc_SVM2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f74052",
   "metadata": {},
   "source": [
    "# Classifier 3 -- k-nearest neighbors (KNN) \n",
    "\n",
    "\n",
    "<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/legnth-ears.JPG\" alt=\"\" width=\"276\" height=\"187\" class=\"blend-mode\">\n",
    "\n",
    "<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/knn.JPG\" alt=\"knn\" width=\"402\" height=\"148\" class=\"blend-mode\">\n",
    "\n",
    "\n",
    ">**How does it actually work**\n",
    "\n",
    "<img loading=\"lazy\" class=\"aligncenter\" src=\"https://editor.analyticsvidhya.com/uploads/369941_-pMkFM7U6GX22WUCLG5g2g.png\" alt=\"K even or odd\" width=\"547\" height=\"378\">\n",
    "\n",
    "**Larger K value:** The case of underfitting occurs when the value of k is increased. In this case, the model would be unable to correctly learn on the training data.\n",
    "\n",
    "**Smaller k value:** The condition of overfitting occurs when the value of k is smaller. The model will capture all of the training data, including noise. The model will perform poorly for the test data in this scenario.\n",
    "\n",
    "<img loading=\"lazy\" class=\"aligncenter\" src=\"https://editor.analyticsvidhya.com/uploads/34077images-1.png\" alt=\"K large or small | KNN\" width=\"393\" height=\"162\">\n",
    "\n",
    "\n",
    ">**Cons:**\n",
    "The KNN algorithm does not work well with large datasets. The cost of calculating the distance between the new point and each existing point is huge, which degrades performance.\n",
    "Feature scaling (standardization and normalization) is required before applying the KNN algorithm to any dataset. Otherwise, KNN may generate wrong predictions.\n",
    "\n",
    "source:\n",
    "1. https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
    "2. https://www.analyticsvidhya.com/blog/2021/05/knn-the-distance-based-machine-learning-algorithm/#:~:text=The%20abbreviation%20KNN%20stands%20for,classification%20and%20regression%20problem%20statements.\n",
    "3.https://rstudio-pubs-static.s3.amazonaws.com/188798_4c808643569c44a3ad06c04f74a32943.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea9d0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96565d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130044843049328"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "modelknn = make_pipeline(TfidfVectorizer(), knn) # we did not remove stopwords here\n",
    "modelknn.fit(SX_train,Sy_train)\n",
    "\n",
    "Sy_predknn = modelknn.predict(SX_test)\n",
    "acc_knn = accuracy_score(Sy_test, Sy_predknn)\n",
    "\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec9eff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90860215 0.91577061 0.91741472 0.91023339 0.91741472 0.91202873\n",
      " 0.91202873 0.91921005 0.91023339 0.92459605]\n",
      "0.9147532544416773\n"
     ]
    }
   ],
   "source": [
    "# using cross_val_score to conduct a 10-fold cross validation \n",
    "KNNcv = cross_val_score(modelknn, X, y, scoring='accuracy', cv=10)\n",
    "print(KNNcv)\n",
    "print(KNNcv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ba55140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question' => ham\n",
      "'Even my brother is not like to speak with me. They treat me like aids patent.' => ham\n",
      "\"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9\" => ham\n",
      "'hello, thank you' => ham\n",
      "'To claim txt DIS to 87121' => ham\n",
      "'SNAP for free pics' => ham\n",
      "'Call 30303 for free prizes!!' => ham\n"
     ]
    }
   ],
   "source": [
    "# let's try some new data with knn classifier\n",
    "\n",
    "docs_new = [\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question\",\n",
    "            \"Even my brother is not like to speak with me. They treat me like aids patent.\",\n",
    "             \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9\",\n",
    "            \"hello, thank you\",\n",
    "           \"To claim txt DIS to 87121\",\n",
    "                \"SNAP for free pics\",\n",
    "           \"Call 30303 for free prizes!!\"]\n",
    "\n",
    "predicted_knn = modelknn.predict(docs_new)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted_knn):\n",
    "    print(('%r => %s' % (doc, category)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b64ab",
   "metadata": {},
   "source": [
    "# Classifier 4 -- Logistic Regression\n",
    "\n",
    "## Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a3d86",
   "metadata": {},
   "source": [
    "<img alt=\"\" class=\"ce mb mc c\" width=\"700\" height=\"311\" loading=\"lazy\" role=\"presentation\" src=\"https://miro.medium.com/max/1400/1*dm6ZaX5fuSmuVvM4Ds-vcg.jpeg\">\n",
    "\n",
    "Logistic regression is a classification algorithm used to assign observations to a discrete set of classes. Some of the examples of classification problems are Email spam or not spam, Online transactions Fraud or not Fraud, Tumor Malignant or Benign. \n",
    "\n",
    "source:\n",
    "1. https://towardsdatascience.com/introduction-to-logistic-regression-66248243c148\n",
    "2. **For more information, please read:** https://developers.google.com/machine-learning/crash-course/logistic-regression/video-lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc0a9893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action 1: using the same logic to build a logistic regression classifier  (Split validation data)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb39912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action 2: using the cross-validation method to build the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea99600",
   "metadata": {},
   "source": [
    "## Action 3 -- build SVM, KNN models to the fetch_20newsgroups dataset, then test the models using articles1.csv, respectively. Which one is better (including the Naive Bayes model, comparing the three models)?\n",
    "\n",
    "## What about using cross-validation method, will it make the model perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d441022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5fa47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3a25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
